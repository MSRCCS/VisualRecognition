RootDir = "."

ConfigDir = "$RootDir$"
DataDir = "$RootDir$"
OutputDir = "$RootDir$/Output"
ModelDir = "$OutputDir$/Models"

ndlMacros="$ConfigDir$/Macros.ndl"

precision="float"
deviceId="Auto"

command=Train:CreateEval:Test

parallelTrain="false"

stderr="$OutputDir$/ResNet_34"
traceLevel=1
numMBsToShowResult=500

Train=[
    action="train"
    modelPath="$ModelDir$/ResNet_34"

    BrainScriptNetworkBuilder = [
		include "$ConfigDir$/macros.bs";

        layout = "cudnn"

        ImageW = 224
        ImageH = 224
        ImageC = 3
        LabelDim = 1000

        features = ImageInput(ImageW, ImageH, ImageC, tag = "feature", imageLayout = layout)
        labels = Input(LabelDim, tag = "label")
    
        # Kernels width and height.
        kW = 3
        kH = 3
        # Kernel stride.
        hs = 1
        vs = 1
    
        # Initial parameter values.
        convWScale = 7.07
        convBValue = 0

        fcWScale = 1.13
        fcBValue = 0

        scValue = 1
    
        # Batch normalization time constant.
        bnTimeConst = 4096

        conv1WScale = 0.6
        cMap1 = 64
        conv1 = ConvBNReLULayer(features, 7, 7, ImageC, cMap1, 2, 2, true, conv1WScale, convBValue, scValue, bnTimeConst).out
        # Max pooling
        pool1W = 3
        pool1H = 3
        pool1hs = 2
        pool1vs = 2
        pool1 = NDPooling(conv1, (pool1W : pool1H : 1), stride=(pool1hs : pool1vs : 1), autoPadding=(true : true : false), imageLayout = layout)
    
        rn1_1 = ResNetNode2A(pool1, kW, kH, cMap1, cMap1, convWScale, convBValue, scValue, bnTimeConst).out
        rn1_2 = ResNetNode2A(rn1_1, kW, kH, cMap1, cMap1, convWScale, convBValue, scValue, bnTimeConst).out
        rn1_3 = ResNetNode2A(rn1_2, kW, kH, cMap1, cMap1, convWScale, convBValue, scValue, bnTimeConst).out

        cMap2 = 128
        rn2_1 = ResNetNode2BInc(rn1_3, kW, kH, cMap1, cMap2, convWScale, convBValue, scValue, bnTimeConst).out
        rn2_2 = ResNetNode2A(   rn2_1, kW, kH, cMap2, cMap2, convWScale, convBValue, scValue, bnTimeConst).out
        rn2_3 = ResNetNode2A(   rn2_2, kW, kH, cMap2, cMap2, convWScale, convBValue, scValue, bnTimeConst).out
        rn2_4 = ResNetNode2A(   rn2_3, kW, kH, cMap2, cMap2, convWScale, convBValue, scValue, bnTimeConst).out

        cMap3 = 256
        rn3_1 = ResNetNode2BInc(rn2_4, kW, kH, cMap2, cMap3, convWScale, convBValue, scValue, bnTimeConst).out
        rn3_2 = ResNetNode2A(   rn3_1, kW, kH, cMap3, cMap3, convWScale, convBValue, scValue, bnTimeConst).out
        rn3_3 = ResNetNode2A(   rn3_2, kW, kH, cMap3, cMap3, convWScale, convBValue, scValue, bnTimeConst).out
        rn3_4 = ResNetNode2A(   rn3_3, kW, kH, cMap3, cMap3, convWScale, convBValue, scValue, bnTimeConst).out
        rn3_5 = ResNetNode2A(   rn3_4, kW, kH, cMap3, cMap3, convWScale, convBValue, scValue, bnTimeConst).out
        rn3_6 = ResNetNode2A(   rn3_5, kW, kH, cMap3, cMap3, convWScale, convBValue, scValue, bnTimeConst).out

        cMap4 = 512
        rn4_1 = ResNetNode2BInc(rn3_6, kW, kH, cMap3, cMap4, convWScale, convBValue, scValue, bnTimeConst).out
        rn4_2 = ResNetNode2A(   rn4_1, kW, kH, cMap4, cMap4, convWScale, convBValue, scValue, bnTimeConst).out
        rn4_3 = ResNetNode2A(   rn4_2, kW, kH, cMap4, cMap4, convWScale, convBValue, scValue, bnTimeConst).out

        # Global average pooling
        pool2W = 7
        pool2H = 7
        pool2hs = 1
        pool2vs = 1
        pool5 = AveragePooling(rn4_3, pool2W, pool2H, pool2hs, pool2vs, imageLayout = "cudnn")

        ol = DnnLayer(cMap4, LabelDim, pool5, fcWScale, fcBValue).out
    
        CE = CrossEntropyWithSoftmax(labels, ol, tag = "criteria")
        Err = ErrorPrediction(labels, ol, tag = "eval")
        OutputNodes = ol

    ]
    
    SGD=[
        epochSize=0
        minibatchSize=256
        # Note that learning rates are 10x more than in the paper due to a different
        # momentum update rule in CNTK: v{t + 1} = lr*(1 - momentum)*g{t + 1} + momentum*v{t}
        learningRatesPerMB=1.0*35:0.1*35:0.01
        momentumPerMB=0.9
        maxEpochs=125
        gradUpdateType="None"
        L2RegWeight=0.0001
        dropoutRate=0
        
        ParallelTrain=[
            parallelizationMethod="DataParallelSGD"
            distributedMBReading="true"
            parallelizationStartEpoch=1
            DataParallelSGD=[
                gradientBits=1
            ]
        ]
    ]
    
    reader=[
        readerType="ImageReader"
        # Map file which maps images to labels using the following format:
        # <full path to image><tab><numerical label (0-based class id)>
        # Example:
        # C:\Data\ImageNet\2012\train\n01440764\n01440764_10026.JPEG<tab>0
        file="$ConfigDir$/train_map.txt"
        # Randomize images before every epoch. Possible values: None, Auto. Default: Auto.
        randomize="Auto"
        features=[
            # Below are the required parameters.
            width=224
            height=224
            channels=3
            # Below are the optional parameters.
            # Possible values: Center, Random. Default: Center
            cropType="Random"
            # Horizontal random flip, will be enabled by default if cropType=Random
            #hflip=0
            # Crop scale ratio. Examples: cropRatio=0.9, cropRatio=0.7:0.9. Default: 1.
            cropRatio=0.46666:0.875
            # Crop scale ratio jitter type.
            # Possible values: None, UniRatio, UniLength, UniArea. Default: UniRatio
            jitterType="UniRatio"
            # Interpolation to use when scaling image to width x height size.
            # Possible values: nearest, linear, cubic, lanczos. Default: linear.
            interpolations="Linear"
            # Stores mean values for each pixel in OpenCV matrix XML format.
            #meanFile="$ConfigDir$/ImageNet1K_mean.xml"
        ]
        labels=[
            labelDim=1000
        ]
    ]    
]

CreateEval=[    
    action="edit"
    CurModel="$ModelDir$/ResNet_34"
    NewModel="$ModelDir$/ResNet_34.Eval"
    editPath="$ConfigDir$/CreateEvalModel.mel"
]

Test=[
    action="test"
    modelPath="$ModelDir$/ResNet_34.Eval"
    # Set minibatch size for testing.
    minibatchSize=64

    reader=[
        readerType="ImageReader"
        file="$ConfigDir$/val_map.txt"
        randomize="None"
        features=[
            width=224
            height=224
            channels=3
            cropType="Center"
            meanFile="$ConfigDir$/ImageNet1K_mean.xml"
        ]
        labels=[
            labelDim=1000
        ]
    ]    
]
